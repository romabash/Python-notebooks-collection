{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Receptive Fields:\n",
    "- Instead of 1D input vector, inputs in convolutional net are 2D\n",
    "- Instead of being Fully connected as in FCNN, small localized regions are connected in CNN\n",
    "- 5x5 region can be connected to a neuron with 25 inputs, each with a learned weight and a neuron bias \n",
    "- A 28x28 input layer with a 5x5 **local receptive field** and *stride length* of 1 results in a 24x24 Hidden Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared Weights and Biases:\n",
    "- Same weights and bias are used for each of the hidden neurons connected to the **local receptive fields**\n",
    "- All the neurons in the hidden layer detect the same feature in different location\n",
    "- Shared weights and bias define a **kernel** or **filter**\n",
    "- A map from input to hidden layer is refered to as *feature map*\n",
    "- Each *feature map* recognize one feature (at different locations in the image) and to recognize several different features, convolutional layers consists of several different *feature maps*\n",
    "- Advantage of sharing weights and biases is that it greatly reduces the number of parameters involved in a convolutional network.  For each 5x5 *feature map* and 1 bias, there are only 26 parameters.  Much less than in a FCNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Layers:\n",
    "- Condense and simplify the information in the output from the convolutional hidden layer and reduces the number of parameters\n",
    "- A 2x2 *max-pooling* layer outputs the maximum activation in the 2×2 input region of the convolutional hidden layer\n",
    "- 24x24 convolutional hidden layer with 2x2 **pooling layer** results in 12x12 neurons\n",
    "- Apply *max-pooling* to each feature map separately:  A 3x24x24 convolution hidden layers, result in 3X12x12 max-pooling layers\n",
    "- Other Pooling methods include *average-pooling* and *L2 pooling* where the square root of the sum of the squares of the activations in the 2×2 region is taken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example CNN:\n",
    "- **28x28 input layer (corresponding to image pixels**\n",
    "    - Convolutional Layer with 5×5 *local receptive field* and 3 feature maps: 3x5x5\n",
    "        - **3×24×24 Hidden feature neurons layer**\n",
    "            - *Max-Pooling* Layer with 2×2 regions across 3 feature maps: 3x2x2\n",
    "                -  **3×12×12 Hidden feature neurons**\n",
    "                    - FCNN, connects every neuron from the 3x12x12 *max-pooled* layer to the 100 neurons hidden layer...\n",
    "- The convolutional and pooling layers learn local spatial structures, while the fully-connected layers learn  more abstract information from across the entire image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
