{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function:\n",
    "- Find *weights* and *biases* to minimize the **Mean Squared Error (MSE)** Cost Function: $C(w,b) \\approx 0 $\n",
    "$$ C(w,b) \\equiv \\frac{1}{2n}\\sum_x \\lVert (x)âˆ’a \\rVert^2$$\n",
    "    - $w$: all weights in the network\n",
    "    - $b$: all the biases\n",
    "    - $n$: is the total number of training inputs\n",
    "    - $a$: is the vector of outputs from the network when $x$ is input\n",
    "    - Sum is over all training inputs, $x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized Cost Function:\n",
    "- Minimize the Cost Function: $C(v) \\approx 0 $\n",
    "- Small changes in parameters $v$ change the Cost Function $C$ as follows:\n",
    "$$ \\Delta C \\approx \\frac{\\partial C}{\\partial v_1} \\Delta v_1 + \\frac{\\partial C}{\\partial v_2} \\Delta v_2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient:\n",
    "- The *Gradient of C* can be written as the vector of partial derivatives of the *Cost Function* with respect to each parameter: \n",
    "$$ \\nabla C \\equiv (\\frac{\\partial C}{\\partial v_1}, \\frac{\\partial C}{\\partial v_2})$$\n",
    "- The changes in parameters $\\Delta v$ can be written as a vector:\n",
    "$$\\Delta v \\equiv (\\Delta v_1, \\Delta v_2, ... \\Delta v_n)$$\n",
    "- The expression for chnage in *Cost Function* $\\Delta C$ can be rewritten as:\n",
    "$$ \\Delta C \\approx \\nabla C \\cdot \\Delta v $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change in $\\Delta v$ and Learning Rate:\n",
    "- To decrease $\\Delta C$, choose $\\Delta v$ to be $\\Delta v = - \\eta \\nabla C$, where $\\eta$ is the **learning rate**\n",
    "- To compute a value for $\\Delta v$:\n",
    "$$ v \\rightarrow v^\\prime = v - \\eta \\nabla C$$\n",
    "- Use the above formula to update after each move in *Gradient Descent*.  Changing the position $v$ in order to find a minimum of the function $C$\n",
    "- Coose the *learning rate* $\\eta$ to be small enough to not increase $\\Delta C$, but not too small which will make the *Gradient Descent* algorithm work very slowly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent with *weights* and *biases*:\n",
    "- The rule which can be used to learn in a neural network:\n",
    "\n",
    "$$ w_k \\rightarrow w_k^\\prime = w_k - \\eta \\frac{\\partial C}{\\partial w_k} $$\n",
    "\n",
    "$$ b_l \\rightarrow b_l^\\prime = b_l - \\eta \\frac{\\partial C}{\\partial b_l} $$\n",
    "\n",
    "- Find a minimum of the *Cost Function* by repeatedly applying the update rule "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent:\n",
    "- With Big Data, *Gradient Descent* can be slow, **Stochastic Gradient Descent** can be used to speed up learning\n",
    "- **Stochastic Gradient Descent** reduces the number of terms that need to be computed\n",
    "- Epecially useful  when there are redundancies in the data\n",
    "- Similar to the **Gradient Descent**, start with a relatively *large* **Learning Rate** and make it *smaller* with each step.  A process called **schedule**\n",
    "- **Stochastic Gradient Descent** uses 1 sample per step, whereas **Mini-batch Gradient Descent** uses a small subset of data at each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Algorithm:\n",
    "1. Take the **Gradient** of the Cost Function - Take the derivative of the Cost Function for each parameter\n",
    "2. Plug the intial parameter values into the **Gradient** (derivatives)\n",
    "3. Calculate the **Step Size**: **Step Size = Slope x Learning Rate**\n",
    "4. Calculate the new parameter values: **New Parameter = Old Parameter - Step Size**\n",
    "5. Repeat Step 3 until **Step Size** is very small or untill **Maximum Number of Steps** is reached "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
